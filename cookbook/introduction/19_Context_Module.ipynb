{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Hawksight-AI/semantica/blob/main/cookbook/introduction/19_Context_Module.ipynb)\n",
        "\n",
        "# Context Engineering Module\n",
        "\n",
        "## Overview\n",
        "\n",
        "This notebook provides a comprehensive guide to Semantica's **Context Engineering Module** - a powerful system for building context graphs, managing agent memory, retrieving context, and linking entities. You'll learn how to use all classes, functions, and submodules to build intelligent agents with persistent memory and context awareness.\n",
        "\n",
        "**Documentation**: [API Reference](https://semantica.readthedocs.io/reference/context/)\n",
        "\n",
        "### Learning Objectives\n",
        "\n",
        "- **Context Graph Construction**: Build dynamic graphs from entities, relationships, and conversations\n",
        "- **Agent Memory Management**: Store and retrieve memories with RAG integration\n",
        "- **Context Retrieval**: Hybrid retrieval combining vector, graph, and memory search\n",
        "- **Entity Linking**: Link entities across documents with URI assignment\n",
        "- **Methods Submodule**: Use convenient functions for all context operations\n",
        "- **Registry System**: Register and use custom context methods\n",
        "- **Configuration**: Manage module settings and method configurations\n",
        "\n",
        "### Key Features\n",
        "\n",
        "- **Context Graphs**: Build graphs from multiple sources (entities, relationships, conversations)\n",
        "- **Agent Memory**: Persistent memory with vector store and knowledge graph integration\n",
        "- **Hybrid Retrieval**: Combine vector, graph, and keyword search for optimal context\n",
        "- **Entity Linking**: Link entities across documents with similarity and graph-based matching\n",
        "- **Method Registry**: Extensible system for custom context methods\n",
        "- **Configuration**: Flexible configuration via environment variables and config files\n",
        "\n",
        "---\n",
        "\n",
        "## Installation\n",
        "\n",
        "Install Semantica from PyPI:\n",
        "\n",
        "```bash\n",
        "pip install semantica\n",
        "# Or with all optional dependencies:\n",
        "pip install semantica[all]\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Module Structure\n",
        "\n",
        "The context module is organized into:\n",
        "\n",
        "- **Main Classes**: `ContextGraphBuilder`, `AgentMemory`, `EntityLinker`, `ContextRetriever`, `AgentContext`\n",
        "- **Methods Submodule**: Convenient functions for all operations (`methods.build_context_graph`, etc.)\n",
        "- **Registry Submodule**: Method registry for custom methods (`registry.method_registry`)\n",
        "- **Config Submodule**: Configuration management (`config.context_config`)\n",
        "\n",
        "Let's explore each component in detail!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Imports and Setup\n",
        "\n",
        "First, let's import all the necessary components from the context module.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import main classes\n",
        "from semantica.context import (\n",
        "    AgentContext,\n",
        "    ContextGraphBuilder,\n",
        "    AgentMemory,\n",
        "    EntityLinker,\n",
        "    ContextRetriever,\n",
        "    ContextNode,\n",
        "    ContextEdge,\n",
        "    MemoryItem,\n",
        "    RetrievedContext\n",
        ")\n",
        "\n",
        "# Import submodules\n",
        "from semantica.context import methods, registry, config\n",
        "\n",
        "# Import methods functions\n",
        "from semantica.context.methods import (\n",
        "    build_context_graph,\n",
        "    store_memory,\n",
        "    retrieve_context,\n",
        "    link_entities,\n",
        "    get_context_method,\n",
        "    list_available_methods\n",
        ")\n",
        "\n",
        "print(\"All context module components imported successfully!\")\n",
        "print(f\"\\nAvailable methods: {list_available_methods()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Quick Start with AgentContext\n",
        "\n",
        "The `AgentContext` class provides a high-level, simplified interface for common use cases. It uses generic method names (`store`, `retrieve`, `forget`, `conversation`) that auto-detect content types and retrieval strategies.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.1 Simple RAG with AgentContext\n",
        "\n",
        "The simplest way to use the context module for RAG.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize AgentContext with vector store\n",
        "context = AgentContext(vector_store=vs)\n",
        "\n",
        "# Store a memory\n",
        "memory_id = context.store(\n",
        "    \"User likes Python programming and machine learning\",\n",
        "    conversation_id=\"conv1\",\n",
        "    user_id=\"user123\"\n",
        ")\n",
        "\n",
        "print(f\"Stored memory with ID: {memory_id}\")\n",
        "\n",
        "# Retrieve context\n",
        "results = context.retrieve(\n",
        "    \"Python programming\",\n",
        "    max_results=5,\n",
        "    use_graph=False  # Boolean flag: force vector-only retrieval\n",
        ")\n",
        "\n",
        "print(f\"\\nRetrieved {len(results)} results\")\n",
        "for i, result in enumerate(results, 1):\n",
        "    print(f\"\\n{i}. Content: {result['content'][:60]}...\")\n",
        "    print(f\"   Score: {result['score']:.2f}\")\n",
        "    print(f\"   Source: {result['source']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.2 GraphRAG with AgentContext\n",
        "\n",
        "Store documents and retrieve with graph context.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize with vector store and knowledge graph\n",
        "context = AgentContext(\n",
        "    vector_store=vs,\n",
        "    knowledge_graph=kg,\n",
        "    use_graph_expansion=True,  # Boolean flag\n",
        "    max_expansion_hops=2\n",
        ")\n",
        "\n",
        "# Store documents (auto-builds graph)\n",
        "documents = [\n",
        "    \"Python is a programming language used for machine learning and data science\",\n",
        "    \"TensorFlow and PyTorch are popular machine learning frameworks\",\n",
        "    \"Machine learning involves training models on data to make predictions\"\n",
        "]\n",
        "\n",
        "stats = context.store(\n",
        "    documents,\n",
        "    extract_entities=True,      # Boolean flag: extract entities\n",
        "    extract_relationships=True,  # Boolean flag: extract relationships\n",
        "    link_entities=True          # Boolean flag: link entities across documents\n",
        ")\n",
        "\n",
        "print(f\"Stored {stats['stored_count']} documents\")\n",
        "print(f\"Built graph with {stats['graph_nodes']} nodes and {stats['graph_edges']} edges\")\n",
        "\n",
        "# Retrieve with graph context (auto-detects GraphRAG)\n",
        "results = context.retrieve(\n",
        "    \"Python machine learning\",\n",
        "    max_results=5,\n",
        "    use_graph=None,              # Auto-detect (uses graph since knowledge_graph available)\n",
        "    include_entities=True,       # Boolean flag: include related entities\n",
        "    include_relationships=False, # Boolean flag: don't include relationships\n",
        "    expand_graph=True            # Boolean flag: use graph expansion\n",
        ")\n",
        "\n",
        "print(f\"\\nRetrieved {len(results)} results with graph context\")\n",
        "for i, result in enumerate(results, 1):\n",
        "    print(f\"\\n{i}. Content: {result['content'][:60]}...\")\n",
        "    print(f\"   Score: {result['score']:.2f}\")\n",
        "    print(f\"   Source: {result['source']}\")\n",
        "    if result.get('related_entities'):\n",
        "        print(f\"   Related entities: {len(result['related_entities'])}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.3 Conversation Management with AgentContext\n",
        "\n",
        "Manage conversation history easily.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "context = AgentContext(vector_store=vs, retention_days=30)\n",
        "\n",
        "# Store multiple memories in a conversation\n",
        "context.store(\"Hello, I'm interested in Python\", conversation_id=\"conv1\", user_id=\"user123\")\n",
        "context.store(\"What can you tell me about machine learning?\", conversation_id=\"conv1\", user_id=\"user123\")\n",
        "context.store(\"I prefer TensorFlow over PyTorch\", conversation_id=\"conv1\", user_id=\"user123\")\n",
        "\n",
        "# Get conversation history\n",
        "history = context.conversation(\n",
        "    \"conv1\",\n",
        "    reverse=True,           # Boolean flag: most recent first\n",
        "    include_metadata=True   # Boolean flag: include full metadata\n",
        ")\n",
        "\n",
        "print(f\"Retrieved {len(history)} items from conversation\")\n",
        "for item in history:\n",
        "    print(f\"   - {item.get('timestamp', 'N/A')}: {item['content']}\")\n",
        "\n",
        "# Retrieve context from conversation\n",
        "results = context.retrieve(\n",
        "    \"Python\",\n",
        "    conversation_id=\"conv1\",  # Filter by conversation\n",
        "    max_results=3\n",
        ")\n",
        "\n",
        "print(f\"\\nRetrieved {len(results)} results from conversation\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.4 Additional Memory Management Methods\n",
        "\n",
        "AgentContext provides many additional methods for memory management, search, and analytics.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Memory Management Methods\n",
        "print(\"=== Memory Management ===\")\n",
        "\n",
        "# Check if memory exists\n",
        "exists = context.exists(memory_id) if memory_id else False\n",
        "print(f\"Memory exists: {exists}\")\n",
        "\n",
        "# Get memory count\n",
        "total = context.count()\n",
        "conv_count = context.count(conversation_id=\"conv1\")\n",
        "print(f\"Total memories: {total}, Conversation memories: {conv_count}\")\n",
        "\n",
        "# Get memory by ID\n",
        "if memory_id:\n",
        "    memory = context.get(memory_id)\n",
        "    if memory:\n",
        "        print(f\"Retrieved memory: {memory['content'][:50]}...\")\n",
        "\n",
        "# Update memory\n",
        "# context.update(memory_id, content=\"Updated content\", metadata={\"key\": \"value\"})\n",
        "\n",
        "# List memories with pagination\n",
        "memories = context.list(conversation_id=\"conv1\", limit=10, offset=0)\n",
        "print(f\"Listed {len(memories)} memories\")\n",
        "\n",
        "# Batch operations\n",
        "# ids = context.batch_store([\"Item 1\", \"Item 2\", \"Item 3\"])\n",
        "# deleted = context.batch_delete([\"mem1\", \"mem2\"])\n",
        "\n",
        "# Search Methods\n",
        "print(\"\\n=== Search Methods ===\")\n",
        "results = context.search(\"Python\", max_results=5)\n",
        "similar = context.find_similar(\"Python programming\", limit=5)\n",
        "context_data = context.get_context(\"Python\", max_results=5)\n",
        "print(f\"Search results: {len(results)}, Similar: {len(similar)}, Context: {len(context_data)}\")\n",
        "\n",
        "# Conversation Methods\n",
        "print(\"\\n=== Conversation Methods ===\")\n",
        "conversations = context.list_conversations(user_id=\"user123\", limit=50)\n",
        "summary = context.conversation_summary(\"conv1\")\n",
        "print(f\"Conversations: {len(conversations)}, Summary: {summary.get('message_count', 0)} messages\")\n",
        "\n",
        "# Export/Import\n",
        "print(\"\\n=== Export/Import ===\")\n",
        "# backup_data = context.backup()\n",
        "# restored = context.restore(backup_data)\n",
        "\n",
        "# Statistics\n",
        "print(\"\\n=== Statistics ===\")\n",
        "stats = context.stats()\n",
        "health = context.health()\n",
        "usage = context.usage_stats(period='day')\n",
        "print(f\"Stats: {stats.get('total_items', 0)} items\")\n",
        "print(f\"Health: {health['status']}\")\n",
        "print(f\"Usage: {usage.get('recent_memories', 0)} recent memories\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Step 3: Context Graph Construction\n",
        "\n",
        "The `ContextGraphBuilder` class allows you to build context graphs from various sources. Let's explore different ways to construct graphs.\n",
        "\n",
        "### 3.1 Building from Entities and Relationships\n",
        "\n",
        "The most straightforward way to build a context graph is from entities and relationships.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize the builder\n",
        "builder = ContextGraphBuilder()\n",
        "\n",
        "# Define entities\n",
        "entities = [\n",
        "    {\"id\": \"e1\", \"text\": \"Python\", \"type\": \"PROGRAMMING_LANGUAGE\", \"confidence\": 0.95},\n",
        "    {\"id\": \"e2\", \"text\": \"Machine Learning\", \"type\": \"CONCEPT\", \"confidence\": 0.9},\n",
        "    {\"id\": \"e3\", \"text\": \"TensorFlow\", \"type\": \"FRAMEWORK\", \"confidence\": 0.92},\n",
        "    {\"id\": \"e4\", \"text\": \"PyTorch\", \"type\": \"FRAMEWORK\", \"confidence\": 0.91},\n",
        "]\n",
        "\n",
        "# Define relationships\n",
        "relationships = [\n",
        "    {\"source_id\": \"e1\", \"target_id\": \"e2\", \"type\": \"used_for\", \"confidence\": 0.9},\n",
        "    {\"source_id\": \"e3\", \"target_id\": \"e2\", \"type\": \"implements\", \"confidence\": 0.95},\n",
        "    {\"source_id\": \"e4\", \"target_id\": \"e2\", \"type\": \"implements\", \"confidence\": 0.94},\n",
        "    {\"source_id\": \"e3\", \"target_id\": \"e1\", \"type\": \"built_with\", \"confidence\": 0.88},\n",
        "    {\"source_id\": \"e4\", \"target_id\": \"e1\", \"type\": \"built_with\", \"confidence\": 0.87},\n",
        "]\n",
        "\n",
        "# Build the graph\n",
        "graph = builder.build_from_entities_and_relationships(entities, relationships)\n",
        "\n",
        "print(f\"Graph built successfully!\")\n",
        "print(f\"Statistics:\")\n",
        "print(f\"   - Nodes: {graph['statistics']['node_count']}\")\n",
        "print(f\"   - Edges: {graph['statistics']['edge_count']}\")\n",
        "print(f\"   - Node types: {list(graph['statistics']['node_types'].keys())}\")\n",
        "print(f\"   - Edge types: {list(graph['statistics']['edge_types'].keys())}\")\n",
        "\n",
        "# Display some nodes\n",
        "print(f\"\\nSample Nodes:\")\n",
        "for node_id, node_data in list(graph['nodes'].items())[:3]:\n",
        "    print(f\"   - {node_id}: {node_data['text']} ({node_data['type']})\")\n",
        "\n",
        "# Display some edges\n",
        "print(f\"\\nSample Edges:\")\n",
        "for edge in list(graph['edges'])[:3]:\n",
        "    print(f\"   - {edge['source_id']} --[{edge['type']}]--> {edge['target_id']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.2 Building from Conversations\n",
        "\n",
        "You can also build graphs from conversation data, which automatically extracts entities, relationships, intents, and sentiments.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define conversations\n",
        "conversations = [\n",
        "    {\n",
        "        \"id\": \"conv1\",\n",
        "        \"content\": \"User asked about Python programming and machine learning\",\n",
        "        \"timestamp\": \"2024-01-01T10:00:00\",\n",
        "        \"entities\": [\n",
        "            {\"id\": \"e1\", \"text\": \"Python\", \"type\": \"PROGRAMMING_LANGUAGE\"},\n",
        "            {\"id\": \"e2\", \"text\": \"Machine Learning\", \"type\": \"CONCEPT\"}\n",
        "        ],\n",
        "        \"relationships\": [\n",
        "            {\"source_id\": \"e1\", \"target_id\": \"e2\", \"type\": \"used_for\"}\n",
        "        ]\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"conv2\",\n",
        "        \"content\": \"User asked about TensorFlow and PyTorch frameworks\",\n",
        "        \"timestamp\": \"2024-01-01T11:00:00\",\n",
        "        \"entities\": [\n",
        "            {\"id\": \"e3\", \"text\": \"TensorFlow\", \"type\": \"FRAMEWORK\"},\n",
        "            {\"id\": \"e4\", \"text\": \"PyTorch\", \"type\": \"FRAMEWORK\"}\n",
        "        ],\n",
        "        \"relationships\": [\n",
        "            {\"source_id\": \"e3\", \"target_id\": \"e4\", \"type\": \"related_to\"}\n",
        "        ]\n",
        "    }\n",
        "]\n",
        "\n",
        "# Build graph from conversations with additional features\n",
        "graph = builder.build_from_conversations(\n",
        "    conversations,\n",
        "    link_entities=True,      # Link similar entities across conversations\n",
        "    extract_intents=True,     # Extract conversation intents\n",
        "    extract_sentiments=True   # Extract sentiment information\n",
        ")\n",
        "\n",
        "print(f\"Graph built from {len(conversations)} conversations!\")\n",
        "print(f\"Statistics:\")\n",
        "print(f\"   - Nodes: {graph['statistics']['node_count']}\")\n",
        "print(f\"   - Edges: {graph['statistics']['edge_count']}\")\n",
        "print(f\"   - Conversations processed: {len(conversations)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.3 Additional Graph Construction Methods\n",
        "\n",
        "ContextGraphBuilder provides high-level methods for easy graph construction.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# High-level construction methods\n",
        "builder = ContextGraphBuilder()\n",
        "\n",
        "# Build from text\n",
        "graph = builder.from_text(\"Python is used for machine learning\")\n",
        "print(f\"From text: {graph.get('statistics', {}).get('node_count', 0)} nodes\")\n",
        "\n",
        "# Build from documents\n",
        "docs = [\"Doc 1 about Python\", \"Doc 2 about ML\"]\n",
        "graph = builder.from_documents(docs)\n",
        "print(f\"From documents: {graph.get('statistics', {}).get('node_count', 0)} nodes\")\n",
        "\n",
        "# Simple add method\n",
        "stats = builder.add(entities=entities, relationships=relationships)\n",
        "print(f\"Add method: {stats.get('node_count', 0)} nodes, {stats.get('edge_count', 0)} edges\")\n",
        "\n",
        "# Query methods\n",
        "results = builder.find(\"Python\")\n",
        "node = builder.find_node(\"e1\")\n",
        "nodes = builder.find_nodes(node_type=\"PROGRAMMING_LANGUAGE\")\n",
        "edges = builder.find_edges(edge_type=\"used_for\")\n",
        "path = builder.find_path(\"e1\", \"e2\", max_hops=5)\n",
        "\n",
        "print(f\"\\nQuery results:\")\n",
        "print(f\"   Find: {len(results)} results\")\n",
        "print(f\"   Find node: {node is not None}\")\n",
        "print(f\"   Find nodes: {len(nodes)} nodes\")\n",
        "print(f\"   Find edges: {len(edges)} edges\")\n",
        "print(f\"   Find path: {len(path)} nodes in path\")\n",
        "\n",
        "# Graph operations\n",
        "subgraph = builder.get_subgraph([\"e1\", \"e2\"])\n",
        "cloned = builder.clone()\n",
        "stats = builder.stats()\n",
        "node_count = builder.node_count(node_type=\"PROGRAMMING_LANGUAGE\")\n",
        "edge_count = builder.edge_count(edge_type=\"used_for\")\n",
        "density = builder.density()\n",
        "\n",
        "print(f\"\\nGraph operations:\")\n",
        "print(f\"   Subgraph: {subgraph.get('statistics', {}).get('node_count', 0)} nodes\")\n",
        "print(f\"   Cloned: {cloned.stats().get('node_count', 0)} nodes\")\n",
        "print(f\"   Stats: {stats.get('node_count', 0)} nodes, {stats.get('edge_count', 0)} edges\")\n",
        "print(f\"   Node count: {node_count}\")\n",
        "print(f\"   Edge count: {edge_count}\")\n",
        "print(f\"   Density: {density:.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Agent Memory Management\n",
        "\n",
        "The `AgentMemory` class provides persistent memory for agents with RAG integration. It stores memories with vector embeddings and integrates with knowledge graphs.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.1 Initializing Agent Memory\n",
        "\n",
        "First, we need to set up a vector store and knowledge graph. For demonstration, we'll use mock objects.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Note: In a real scenario, you would use actual vector store and knowledge graph instances\n",
        "# For demonstration, we'll create mock objects\n",
        "\n",
        "class MockVectorStore:\n",
        "    \"\"\"Mock vector store for demonstration.\"\"\"\n",
        "    def __init__(self):\n",
        "        self.vectors = {}\n",
        "        self.metadata = {}\n",
        "    \n",
        "    def add(self, ids, embeddings, metadatas=None):\n",
        "        for i, id_val in enumerate(ids):\n",
        "            self.vectors[id_val] = embeddings[i]\n",
        "            if metadatas:\n",
        "                self.metadata[id_val] = metadatas[i]\n",
        "    \n",
        "    def query(self, query_embeddings, n_results=5, where=None):\n",
        "        # Simplified mock query\n",
        "        results = []\n",
        "        for i, (id_val, vector) in enumerate(list(self.vectors.items())[:n_results]):\n",
        "            results.append({\n",
        "                'id': id_val,\n",
        "                'score': 0.9 - i * 0.1,\n",
        "                'metadata': self.metadata.get(id_val, {})\n",
        "            })\n",
        "        return {'ids': [[r['id'] for r in results]], 'metadatas': [[r['metadata'] for r in results]]}\n",
        "\n",
        "class MockKnowledgeGraph:\n",
        "    \"\"\"Mock knowledge graph for demonstration.\"\"\"\n",
        "    def __init__(self):\n",
        "        self.entities = {}\n",
        "        self.relationships = []\n",
        "        self.nodes = []\n",
        "        self.edges = []\n",
        "    \n",
        "    def add_entity(self, entity_id, entity_data):\n",
        "        self.entities[entity_id] = entity_data\n",
        "    \n",
        "    def add_relationship(self, source, target, rel_type):\n",
        "        self.relationships.append({\n",
        "            'source_id': source,\n",
        "            'target_id': target,\n",
        "            'type': rel_type\n",
        "        })\n",
        "\n",
        "# Initialize mock stores\n",
        "vs = MockVectorStore()\n",
        "kg = MockKnowledgeGraph()\n",
        "\n",
        "# Initialize AgentMemory\n",
        "memory = AgentMemory(\n",
        "    vector_store=vs,\n",
        "    knowledge_graph=kg,\n",
        "    retention_policy=\"30_days\",  # Keep memories for 30 days\n",
        "    max_memory_size=10000         # Maximum number of memories\n",
        ")\n",
        "\n",
        "print(\"AgentMemory initialized successfully!\")\n",
        "print(f\"Configuration:\")\n",
        "print(f\"   - Retention policy: 30_days\")\n",
        "print(f\"   - Max memory size: 10000\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.2 Storing Memories\n",
        "\n",
        "Store memories with metadata and associated entities.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Store a memory with metadata\n",
        "memory_id = memory.store(\n",
        "    \"User asked about Python programming and machine learning\",\n",
        "    metadata={\n",
        "        \"type\": \"conversation\",\n",
        "        \"conversation_id\": \"conv_123\",\n",
        "        \"user_id\": \"user_456\",\n",
        "        \"timestamp\": \"2024-01-01T10:00:00\"\n",
        "    },\n",
        "    entities=[\n",
        "        {\"id\": \"e1\", \"text\": \"Python\", \"type\": \"PROGRAMMING_LANGUAGE\"},\n",
        "        {\"id\": \"e2\", \"text\": \"Machine Learning\", \"type\": \"CONCEPT\"}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(f\"Memory stored with ID: {memory_id}\")\n",
        "\n",
        "# Store another memory\n",
        "memory_id_2 = memory.store(\n",
        "    \"User asked about TensorFlow framework for deep learning\",\n",
        "    metadata={\n",
        "        \"type\": \"conversation\",\n",
        "        \"conversation_id\": \"conv_124\",\n",
        "        \"user_id\": \"user_456\"\n",
        "    },\n",
        "    entities=[\n",
        "        {\"id\": \"e3\", \"text\": \"TensorFlow\", \"type\": \"FRAMEWORK\"},\n",
        "        {\"id\": \"e2\", \"text\": \"Deep Learning\", \"type\": \"CONCEPT\"}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(f\"Second memory stored with ID: {memory_id_2}\")\n",
        "\n",
        "# Get statistics\n",
        "stats = memory.get_statistics()\n",
        "print(f\"\\nMemory Statistics:\")\n",
        "print(f\"   - Total items: {stats['total_items']}\")\n",
        "print(f\"   - Items by type: {stats.get('items_by_type', {})}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.3 Additional Memory Management Methods\n",
        "\n",
        "AgentMemory provides many additional methods for memory operations.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Basic operations\n",
        "print(\"=== Basic Operations ===\")\n",
        "exists = memory.exists(memory_id) if memory_id else False\n",
        "count = memory.count()\n",
        "mem = memory.get(memory_id) if memory_id else None\n",
        "print(f\"Exists: {exists}, Count: {count}, Retrieved: {mem is not None}\")\n",
        "\n",
        "# Search methods\n",
        "print(\"\\n=== Search Methods ===\")\n",
        "results = memory.search(\"Python\", max_results=5)\n",
        "similar = memory.find_similar(\"Python programming\", limit=5)\n",
        "by_entity = memory.find_by_entity(\"e1\", limit=10)\n",
        "by_relationship = memory.find_by_relationship(\"used_for\", limit=10)\n",
        "print(f\"Search: {len(results)}, Similar: {len(similar)}, By entity: {len(by_entity)}, By relationship: {len(by_relationship)}\")\n",
        "\n",
        "# List and filter methods\n",
        "print(\"\\n=== List and Filter Methods ===\")\n",
        "memories = memory.list(conversation_id=\"conv_123\", limit=10)\n",
        "conv_memories = memory.get_by_conversation(\"conv_123\", limit=100)\n",
        "user_memories = memory.get_by_user(\"user_456\", limit=100)\n",
        "recent = memory.get_recent(limit=10)\n",
        "print(f\"List: {len(memories)}, Conversation: {len(conv_memories)}, User: {len(user_memories)}, Recent: {len(recent)}\")\n",
        "\n",
        "# Batch operations\n",
        "print(\"\\n=== Batch Operations ===\")\n",
        "# ids = memory.batch_store([\"Item 1\", \"Item 2\"])\n",
        "# deleted = memory.batch_delete([\"mem1\", \"mem2\"])\n",
        "# updated = memory.batch_update([{\"memory_id\": \"mem1\", \"content\": \"New\"}])\n",
        "\n",
        "# Statistics\n",
        "print(\"\\n=== Statistics ===\")\n",
        "stats = memory.stats()\n",
        "type_counts = memory.count_by_type()\n",
        "user_counts = memory.count_by_user()\n",
        "conv_counts = memory.count_by_conversation()\n",
        "print(f\"Stats: {stats.get('total_items', 0)} items\")\n",
        "print(f\"By type: {type_counts}\")\n",
        "print(f\"By user: {user_counts}\")\n",
        "print(f\"By conversation: {conv_counts}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.4 Conversation History\n",
        "\n",
        "Retrieve conversation history for a specific conversation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get conversation history\n",
        "history = memory.get_conversation_history(\n",
        "    conversation_id=\"conv_123\",\n",
        "    max_items=100\n",
        ")\n",
        "\n",
        "print(f\"Retrieved {len(history)} items from conversation history\")\n",
        "for item in history:\n",
        "    print(f\"   - {item.get('timestamp', 'N/A')}: {item.get('content', '')[:50]}...\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.5 Memory Management\n",
        "\n",
        "Delete and manage memories with various filters.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Delete a specific memory\n",
        "if memory_id_2:\n",
        "    memory.delete(memory_id_2)\n",
        "    print(f\"Deleted memory: {memory_id_2}\")\n",
        "\n",
        "# Clear memories by filters\n",
        "deleted_count = memory.clear(\n",
        "    type=\"conversation\",\n",
        "    start_date=\"2024-01-01\",\n",
        "    end_date=\"2024-12-31\"\n",
        ")\n",
        "\n",
        "print(f\"Cleared {deleted_count} memories matching filters\")\n",
        "\n",
        "# Get updated statistics\n",
        "stats = memory.get_statistics()\n",
        "print(f\"\\nUpdated Statistics:\")\n",
        "print(f\"   - Total items: {stats['total_items']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Context Retrieval\n",
        "\n",
        "The `ContextRetriever` class provides hybrid context retrieval combining vector search, graph traversal, and memory search.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.1 Basic Context Retrieval\n",
        "\n",
        "Initialize and use the context retriever for hybrid retrieval.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize ContextRetriever\n",
        "retriever = ContextRetriever(\n",
        "    memory_store=memory,\n",
        "    knowledge_graph=kg,\n",
        "    vector_store=vs,\n",
        "    use_graph_expansion=True,  # Enable graph expansion for related entities\n",
        "    max_expansion_hops=2        # Maximum hops for graph expansion\n",
        ")\n",
        "\n",
        "# Retrieve context\n",
        "results = retriever.retrieve(\n",
        "    \"Python programming\",\n",
        "    max_results=5,\n",
        "    min_relevance_score=0.5\n",
        ")\n",
        "\n",
        "print(f\"Retrieved {len(results)} context items\")\n",
        "print(f\"\\nResults:\")\n",
        "for i, result in enumerate(results, 1):\n",
        "    print(f\"\\n{i}. Content: {result.content[:60]}...\")\n",
        "    print(f\"   Score: {result.score:.2f}\")\n",
        "    print(f\"   Source: {result.source}\")\n",
        "    print(f\"   Related entities: {len(result.related_entities)}\")\n",
        "    if result.related_entities:\n",
        "        print(f\"   - {', '.join([e.get('content', '') for e in result.related_entities[:3]])}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.2 Additional Retrieval Methods\n",
        "\n",
        "ContextRetriever provides many additional methods for different retrieval strategies.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Search methods\n",
        "print(\"=== Search Methods ===\")\n",
        "results = retriever.search(\"Python\", max_results=5)\n",
        "vector_results = retriever.vector_search(\"Python\")\n",
        "graph_results = retriever.graph_search(\"Python\")\n",
        "memory_results = retriever.memory_search(\"Python\")\n",
        "hybrid_results = retriever.hybrid_search(\"Python\")\n",
        "print(f\"Search: {len(results)}, Vector: {len(vector_results)}, Graph: {len(graph_results)}, Memory: {len(memory_results)}, Hybrid: {len(hybrid_results)}\")\n",
        "\n",
        "# Advanced retrieval\n",
        "print(\"\\n=== Advanced Retrieval ===\")\n",
        "similar = retriever.find_similar(\"Python programming\", limit=5)\n",
        "context = retriever.get_context(\"Python\", max_results=5)\n",
        "expanded = retriever.expand_query(\"Python\", max_hops=2)\n",
        "related = retriever.get_related(\"e1\", max_hops=2) if hasattr(kg, 'nodes') else []\n",
        "path = retriever.get_path(\"e1\", \"e2\", max_hops=5) if hasattr(kg, 'nodes') else []\n",
        "print(f\"Similar: {len(similar)}, Context: {len(context)}, Expanded: {len(expanded)}, Related: {len(related)}, Path: {len(path)}\")\n",
        "\n",
        "# Filter methods\n",
        "print(\"\\n=== Filter Methods ===\")\n",
        "# by_entity = retriever.filter_by_entity(\"e1\", \"Python\")\n",
        "# by_type = retriever.filter_by_type(\"PROGRAMMING_LANGUAGE\", \"Python\")\n",
        "# by_date = retriever.filter_by_date(\"2024-01-01\", \"2024-12-31\", \"Python\")\n",
        "# by_score = retriever.filter_by_score(0.7, \"Python\")\n",
        "\n",
        "# Batch operations\n",
        "print(\"\\n=== Batch Operations ===\")\n",
        "# batch_results = retriever.batch_search([\"Python\", \"Java\", \"C++\"])\n",
        "# batch_contexts = retriever.batch_get_context([\"Python\", \"Java\"], max_results=5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Entity Linking\n",
        "\n",
        "The `EntityLinker` class links entities across documents with URI assignment and similarity matching.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6.1 Basic Entity Linking\n",
        "\n",
        "Link entities in text and assign URIs.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize EntityLinker\n",
        "linker = EntityLinker(\n",
        "    knowledge_graph=kg,\n",
        "    similarity_threshold=0.8,\n",
        "    base_uri=\"https://semantica.dev/entity/\"\n",
        ")\n",
        "\n",
        "# Assign URI to an entity\n",
        "uri = linker.assign_uri(\n",
        "    \"entity_1\",\n",
        "    \"Python\",\n",
        "    \"PROGRAMMING_LANGUAGE\"\n",
        ")\n",
        "print(f\"Assigned URI: {uri}\")\n",
        "\n",
        "# Link entities in text\n",
        "entities = [\n",
        "    {\"id\": \"e1\", \"text\": \"Python\", \"type\": \"PROGRAMMING_LANGUAGE\"},\n",
        "    {\"id\": \"e2\", \"text\": \"Machine Learning\", \"type\": \"CONCEPT\"},\n",
        "]\n",
        "\n",
        "linked_entities = linker.link(\n",
        "    \"Python is used for machine learning\",\n",
        "    entities=entities\n",
        ")\n",
        "\n",
        "print(f\"\\nLinked {len(linked_entities)} entities\")\n",
        "for entity in linked_entities:\n",
        "    print(f\"   - {entity.text}: {entity.uri}\")\n",
        "    print(f\"     Linked to {len(entity.linked_entities)} entities\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6.2 Additional Entity Linking Methods\n",
        "\n",
        "EntityLinker provides many additional methods for linking and searching entities.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create explicit link between entities\n",
        "linker.link_entities(\n",
        "    \"entity_1\",\n",
        "    \"entity_2\",\n",
        "    link_type=\"related_to\",\n",
        "    confidence=0.9,\n",
        "    source=\"manual\"\n",
        ")\n",
        "\n",
        "# Get entity links\n",
        "links = linker.get_entity_links(\"entity_1\")\n",
        "print(f\"‚úÖ Found {len(links)} links for entity_1\")\n",
        "for link in links:\n",
        "    print(f\"   - {link.source_entity_id} --[{link.link_type}]--> {link.target_entity_id}\")\n",
        "\n",
        "# Get entity URI\n",
        "uri = linker.get_entity_uri(\"entity_1\")\n",
        "if uri:\n",
        "    print(f\"\\n‚úÖ Entity URI: {uri}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.3 Finding Similar Entities\n",
        "\n",
        "Find similar entities using similarity matching.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Find similar entities\n",
        "similar = linker.find_similar_entities(\n",
        "    \"Python\",\n",
        "    entity_type=\"PROGRAMMING_LANGUAGE\",\n",
        "    threshold=0.8\n",
        ")\n",
        "\n",
        "print(f\"‚úÖ Found {len(similar)} similar entities\")\n",
        "for entity_id, similarity in similar:\n",
        "    print(f\"   - {entity_id}: {similarity:.2f} similarity\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.4 Building Entity Web\n",
        "\n",
        "Build a complete entity web showing all connections.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Link multiple entities\n",
        "linker.link_entities(\"e1\", \"e2\", \"related_to\", confidence=0.9)\n",
        "linker.link_entities(\"e2\", \"e3\", \"related_to\", confidence=0.85)\n",
        "\n",
        "# Build entity web\n",
        "web = linker.build_entity_web()\n",
        "\n",
        "print(f\"‚úÖ Entity Web Statistics:\")\n",
        "print(f\"   - Total entities: {web['statistics']['total_entities']}\")\n",
        "print(f\"   - Total links: {web['statistics']['total_links']}\")\n",
        "\n",
        "for entity_id, info in list(web['entities'].items())[:5]:\n",
        "    print(f\"\\n   Entity {entity_id}:\")\n",
        "    print(f\"     - URI: {info.get('uri', 'N/A')}\")\n",
        "    print(f\"     - Links: {info.get('links', 0)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéØ Step 6: Methods Submodule\n",
        "\n",
        "The `methods` submodule provides convenient functions for all context operations. These functions use the method registry system and support multiple algorithms.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6.1 Building Context Graphs with Methods\n",
        "\n",
        "Use the `build_context_graph` function with different methods.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build from entities and relationships\n",
        "graph = methods.build_context_graph(\n",
        "    entities=entities,\n",
        "    relationships=relationships,\n",
        "    method=\"entities_relationships\"\n",
        ")\n",
        "\n",
        "print(f\"‚úÖ Built graph using 'entities_relationships' method\")\n",
        "print(f\"   - Nodes: {graph['statistics']['node_count']}\")\n",
        "print(f\"   - Edges: {graph['statistics']['edge_count']}\")\n",
        "\n",
        "# Build from conversations\n",
        "graph = methods.build_context_graph(\n",
        "    conversations=conversations,\n",
        "    method=\"conversations\"\n",
        ")\n",
        "\n",
        "print(f\"\\n‚úÖ Built graph using 'conversations' method\")\n",
        "print(f\"   - Nodes: {graph['statistics']['node_count']}\")\n",
        "\n",
        "# Hybrid construction\n",
        "graph = methods.build_context_graph(\n",
        "    entities=entities,\n",
        "    relationships=relationships,\n",
        "    conversations=conversations,\n",
        "    method=\"hybrid\"\n",
        ")\n",
        "\n",
        "print(f\"\\n‚úÖ Built graph using 'hybrid' method\")\n",
        "print(f\"   - Nodes: {graph['statistics']['node_count']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6.2 Storing Memories with Methods\n",
        "\n",
        "Use the `store_memory` function with different storage methods.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Store memory using method\n",
        "memory_id = methods.store_memory(\n",
        "    \"User asked about Python programming\",\n",
        "    vector_store=vs,\n",
        "    knowledge_graph=kg,\n",
        "    method=\"store\",\n",
        "    metadata={\"type\": \"conversation\"}\n",
        ")\n",
        "\n",
        "print(f\"‚úÖ Stored memory with ID: {memory_id}\")\n",
        "\n",
        "# Store conversation memory\n",
        "memory_id = methods.store_memory(\n",
        "    \"User asked about machine learning frameworks\",\n",
        "    vector_store=vs,\n",
        "    knowledge_graph=kg,\n",
        "    method=\"conversation\",\n",
        "    metadata={\"conversation_id\": \"conv_125\"}\n",
        ")\n",
        "\n",
        "print(f\"‚úÖ Stored conversation memory with ID: {memory_id}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6.3 Retrieving Context with Methods\n",
        "\n",
        "Use the `retrieve_context` function with different retrieval methods.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vector-based retrieval only\n",
        "results = methods.retrieve_context(\n",
        "    \"Python programming\",\n",
        "    vector_store=vs,\n",
        "    method=\"vector\",\n",
        "    max_results=5\n",
        ")\n",
        "print(f\"‚úÖ Vector retrieval: {len(results)} results\")\n",
        "\n",
        "# Graph-based retrieval only\n",
        "results = methods.retrieve_context(\n",
        "    \"Python programming\",\n",
        "    knowledge_graph=kg,\n",
        "    method=\"graph\",\n",
        "    max_results=5\n",
        ")\n",
        "print(f\"‚úÖ Graph retrieval: {len(results)} results\")\n",
        "\n",
        "# Memory-based retrieval only\n",
        "results = methods.retrieve_context(\n",
        "    \"Python programming\",\n",
        "    memory_store=memory,\n",
        "    method=\"memory\",\n",
        "    max_results=5\n",
        ")\n",
        "print(f\"‚úÖ Memory retrieval: {len(results)} results\")\n",
        "\n",
        "# Hybrid retrieval (all sources)\n",
        "results = methods.retrieve_context(\n",
        "    \"Python programming\",\n",
        "    memory_store=memory,\n",
        "    knowledge_graph=kg,\n",
        "    vector_store=vs,\n",
        "    method=\"hybrid\",\n",
        "    max_results=5\n",
        ")\n",
        "print(f\"‚úÖ Hybrid retrieval: {len(results)} results\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6.4 Linking Entities with Methods\n",
        "\n",
        "Use the `link_entities` function with different linking methods.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# URI assignment only\n",
        "linked = methods.link_entities(\n",
        "    entities,\n",
        "    method=\"uri\"\n",
        ")\n",
        "print(f\"‚úÖ URI linking: {len(linked)} entities linked\")\n",
        "\n",
        "# Similarity-based linking\n",
        "linked = methods.link_entities(\n",
        "    entities,\n",
        "    knowledge_graph=kg,\n",
        "    method=\"similarity\"\n",
        ")\n",
        "print(f\"‚úÖ Similarity linking: {len(linked)} entities linked\")\n",
        "\n",
        "# Knowledge graph-based linking\n",
        "linked = methods.link_entities(\n",
        "    entities,\n",
        "    knowledge_graph=kg,\n",
        "    method=\"knowledge_graph\"\n",
        ")\n",
        "print(f\"‚úÖ Knowledge graph linking: {len(linked)} entities linked\")\n",
        "\n",
        "# Cross-document linking\n",
        "linked = methods.link_entities(\n",
        "    entities,\n",
        "    knowledge_graph=kg,\n",
        "    method=\"cross_document\",\n",
        "    context=[{\"source\": \"doc1\"}, {\"source\": \"doc2\"}]\n",
        ")\n",
        "print(f\"‚úÖ Cross-document linking: {len(linked)} entities linked\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6.5 Listing Available Methods\n",
        "\n",
        "Discover all available methods for different tasks.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# List all available methods\n",
        "all_methods = methods.list_available_methods()\n",
        "print(\"üìã All Available Methods:\")\n",
        "for task, method_list in all_methods.items():\n",
        "    print(f\"   {task}: {method_list}\")\n",
        "\n",
        "# List methods for specific task\n",
        "graph_methods = methods.list_available_methods(\"graph\")\n",
        "print(f\"\\nüìä Graph Methods: {graph_methods}\")\n",
        "\n",
        "# Get a specific method\n",
        "custom_method = methods.get_context_method(\"graph\", \"entities_relationships\")\n",
        "if custom_method:\n",
        "    print(f\"\\n‚úÖ Retrieved method: {custom_method.__name__}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéõÔ∏è Step 7: Registry Submodule\n",
        "\n",
        "The `registry` submodule allows you to register custom context methods for extensibility.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 7.1 Registering Custom Methods\n",
        "\n",
        "Register your own custom context methods.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define a custom graph builder function\n",
        "def custom_graph_builder(entities, relationships, **kwargs):\n",
        "    \"\"\"Custom graph building method with additional processing.\"\"\"\n",
        "    # Custom implementation\n",
        "    nodes = {}\n",
        "    edges = []\n",
        "    \n",
        "    # Process entities\n",
        "    for entity in entities:\n",
        "        nodes[entity['id']] = {\n",
        "            'text': entity.get('text', ''),\n",
        "            'type': entity.get('type', ''),\n",
        "            'confidence': entity.get('confidence', 1.0)\n",
        "        }\n",
        "    \n",
        "    # Process relationships\n",
        "    for rel in relationships:\n",
        "        edges.append({\n",
        "            'source_id': rel['source_id'],\n",
        "            'target_id': rel['target_id'],\n",
        "            'type': rel['type'],\n",
        "            'weight': rel.get('confidence', 1.0)\n",
        "        })\n",
        "    \n",
        "    return {\n",
        "        'nodes': nodes,\n",
        "        'edges': edges,\n",
        "        'statistics': {\n",
        "            'node_count': len(nodes),\n",
        "            'edge_count': len(edges)\n",
        "        }\n",
        "    }\n",
        "\n",
        "# Register custom method\n",
        "registry.method_registry.register(\"graph\", \"custom_builder\", custom_graph_builder)\n",
        "\n",
        "print(\"‚úÖ Registered custom method: 'custom_builder'\")\n",
        "\n",
        "# Use custom method\n",
        "graph = methods.build_context_graph(\n",
        "    entities=entities,\n",
        "    relationships=relationships,\n",
        "    method=\"custom_builder\"\n",
        ")\n",
        "\n",
        "print(f\"‚úÖ Built graph using custom method\")\n",
        "print(f\"   - Nodes: {graph['statistics']['node_count']}\")\n",
        "print(f\"   - Edges: {graph['statistics']['edge_count']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 7.2 Managing Registered Methods\n",
        "\n",
        "List and manage registered methods.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# List all registered methods for a task\n",
        "methods_list = registry.method_registry.list_all(\"graph\")\n",
        "print(f\"üìã Registered graph methods: {methods_list}\")\n",
        "\n",
        "# Get a registered method\n",
        "retrieved_method = registry.method_registry.get(\"graph\", \"custom_builder\")\n",
        "if retrieved_method:\n",
        "    print(f\"‚úÖ Retrieved method: {retrieved_method.__name__}\")\n",
        "\n",
        "# Unregister a method\n",
        "registry.method_registry.unregister(\"graph\", \"custom_builder\")\n",
        "print(f\"‚úÖ Unregistered method: 'custom_builder'\")\n",
        "\n",
        "# Verify unregistration\n",
        "methods_list = registry.method_registry.list_all(\"graph\")\n",
        "print(f\"üìã Updated methods list: {methods_list}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ‚öôÔ∏è Step 8: Configuration Submodule\n",
        "\n",
        "The `config` submodule provides centralized configuration management for the context module.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 8.1 Basic Configuration\n",
        "\n",
        "Get and set configuration values.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get configuration values\n",
        "retention = config.context_config.get(\"retention_policy\", default=\"unlimited\")\n",
        "max_size = config.context_config.get(\"max_memory_size\", default=10000)\n",
        "\n",
        "print(f\"üìã Current Configuration:\")\n",
        "print(f\"   - Retention policy: {retention}\")\n",
        "print(f\"   - Max memory size: {max_size}\")\n",
        "\n",
        "# Set configuration values\n",
        "config.context_config.set(\"retention_policy\", \"30_days\")\n",
        "config.context_config.set(\"max_memory_size\", 5000)\n",
        "\n",
        "print(f\"\\n‚úÖ Updated Configuration:\")\n",
        "print(f\"   - Retention policy: {config.context_config.get('retention_policy')}\")\n",
        "print(f\"   - Max memory size: {config.context_config.get('max_memory_size')}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 8.2 Method-Specific Configuration\n",
        "\n",
        "Configure settings for specific methods.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set method-specific configuration\n",
        "config.context_config.set_method_config(\"graph\", {\n",
        "    \"extract_entities\": True,\n",
        "    \"extract_relationships\": True,\n",
        "    \"max_depth\": 3\n",
        "})\n",
        "\n",
        "# Get method-specific configuration\n",
        "method_config = config.context_config.get_method_config(\"graph\")\n",
        "print(f\"üìã Graph Method Configuration:\")\n",
        "print(f\"   {method_config}\")\n",
        "\n",
        "# Set memory method configuration\n",
        "config.context_config.set_method_config(\"memory\", {\n",
        "    \"retention_policy\": \"unlimited\",\n",
        "    \"embedding_dimensions\": 1536\n",
        "})\n",
        "\n",
        "memory_config = config.context_config.get_method_config(\"memory\")\n",
        "print(f\"\\nüìã Memory Method Configuration:\")\n",
        "print(f\"   {memory_config}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 8.3 Getting All Configuration\n",
        "\n",
        "Retrieve all configuration values at once.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get all configurations\n",
        "all_configs = config.context_config.get_all()\n",
        "\n",
        "print(f\"üìã All Configuration Values:\")\n",
        "for key, value in all_configs.items():\n",
        "    if isinstance(value, dict):\n",
        "        print(f\"   {key}:\")\n",
        "        for sub_key, sub_value in value.items():\n",
        "            print(f\"      {sub_key}: {sub_value}\")\n",
        "    else:\n",
        "        print(f\"   {key}: {value}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 8.4 Environment Variables\n",
        "\n",
        "Configuration can also be set via environment variables. The module automatically reads:\n",
        "- `CONTEXT_RETENTION_POLICY`\n",
        "- `CONTEXT_MAX_MEMORY_SIZE`\n",
        "- `CONTEXT_SIMILARITY_THRESHOLD`\n",
        "- And more...\n",
        "\n",
        "```bash\n",
        "# Example environment variable setup\n",
        "export CONTEXT_RETENTION_POLICY=30_days\n",
        "export CONTEXT_MAX_MEMORY_SIZE=5000\n",
        "export CONTEXT_SIMILARITY_THRESHOLD=0.8\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üöÄ Step 9: Advanced Examples\n",
        "\n",
        "Let's combine everything we've learned into complete workflows for building intelligent agents with context awareness.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 9.1 Complete Agent Context Workflow\n",
        "\n",
        "A complete workflow from building context graphs to retrieving context for agent responses.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 1: Build context graph from entities and relationships\n",
        "builder = ContextGraphBuilder()\n",
        "graph = builder.build_from_entities_and_relationships(entities, relationships)\n",
        "\n",
        "print(f\"‚úÖ Step 1: Built context graph with {graph['statistics']['node_count']} nodes\")\n",
        "\n",
        "# Step 2: Initialize agent memory\n",
        "memory = AgentMemory(vector_store=vs, knowledge_graph=kg)\n",
        "\n",
        "# Step 3: Store conversation in memory\n",
        "conversation_id = \"conv_126\"\n",
        "memory_id = memory.store(\n",
        "    \"User asked about Python programming and machine learning frameworks\",\n",
        "    metadata={\n",
        "        \"type\": \"conversation\",\n",
        "        \"conversation_id\": conversation_id,\n",
        "        \"user_id\": \"user_789\",\n",
        "        \"timestamp\": \"2024-01-01T12:00:00\"\n",
        "    },\n",
        "    entities=[\n",
        "        {\"id\": \"e1\", \"text\": \"Python\", \"type\": \"PROGRAMMING_LANGUAGE\"},\n",
        "        {\"id\": \"e2\", \"text\": \"Machine Learning\", \"type\": \"CONCEPT\"}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(f\"‚úÖ Step 2-3: Stored conversation memory with ID: {memory_id}\")\n",
        "\n",
        "# Step 4: Link entities\n",
        "linker = EntityLinker(knowledge_graph=kg)\n",
        "linked = linker.link(\n",
        "    \"Python is used for machine learning\",\n",
        "    entities=entities\n",
        ")\n",
        "\n",
        "print(f\"‚úÖ Step 4: Linked {len(linked)} entities\")\n",
        "\n",
        "# Step 5: Retrieve context for agent response\n",
        "retriever = ContextRetriever(\n",
        "    memory_store=memory,\n",
        "    knowledge_graph=kg,\n",
        "    vector_store=vs\n",
        ")\n",
        "\n",
        "results = retriever.retrieve(\"Python programming\", max_results=5)\n",
        "\n",
        "print(f\"‚úÖ Step 5: Retrieved {len(results)} context items\")\n",
        "print(f\"\\nüìã Context for Agent Response:\")\n",
        "for i, result in enumerate(results[:3], 1):\n",
        "    print(f\"\\n{i}. {result.content[:60]}...\")\n",
        "    print(f\"   Score: {result.score:.2f}, Source: {result.source}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize retriever with multiple sources\n",
        "retriever = ContextRetriever(\n",
        "    memory_store=memory,\n",
        "    knowledge_graph=kg,\n",
        "    vector_store=vs,\n",
        "    hybrid_alpha=0.5,  # Balance between vector and graph\n",
        "    use_graph_expansion=True,\n",
        "    max_expansion_hops=2\n",
        ")\n",
        "\n",
        "# Retrieve with hybrid approach\n",
        "results = retriever.retrieve(\n",
        "    \"Python machine learning frameworks\",\n",
        "    max_results=10,\n",
        "    use_graph_expansion=True,\n",
        "    max_hops=2\n",
        ")\n",
        "\n",
        "print(f\"‚úÖ Retrieved {len(results)} results from multiple sources\")\n",
        "print(f\"\\nüìã Multi-Source Results:\")\n",
        "for i, result in enumerate(results[:5], 1):\n",
        "    print(f\"\\n{i}. Source: {result.source}\")\n",
        "    print(f\"   Content: {result.content[:80]}...\")\n",
        "    print(f\"   Score: {result.score:.2f}\")\n",
        "    print(f\"   Related entities: {len(result.related_entities)}\")\n",
        "    if result.related_entities:\n",
        "        print(f\"   - {', '.join([e.get('content', '') for e in result.related_entities[:3]])}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 9.3 Conversation-Based Context Building\n",
        "\n",
        "Build context graphs from conversation history and maintain conversation context.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Process multiple conversations\n",
        "conversations = [\n",
        "    {\n",
        "        \"id\": \"conv1\",\n",
        "        \"content\": \"User asked about Python programming\",\n",
        "        \"timestamp\": \"2024-01-01T10:00:00\",\n",
        "        \"entities\": [{\"id\": \"e1\", \"text\": \"Python\", \"type\": \"PROGRAMMING_LANGUAGE\"}]\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"conv2\",\n",
        "        \"content\": \"User asked about machine learning\",\n",
        "        \"timestamp\": \"2024-01-01T11:00:00\",\n",
        "        \"entities\": [{\"id\": \"e2\", \"text\": \"Machine Learning\", \"type\": \"CONCEPT\"}]\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"conv3\",\n",
        "        \"content\": \"User asked about TensorFlow and PyTorch\",\n",
        "        \"timestamp\": \"2024-01-01T12:00:00\",\n",
        "        \"entities\": [\n",
        "            {\"id\": \"e3\", \"text\": \"TensorFlow\", \"type\": \"FRAMEWORK\"},\n",
        "            {\"id\": \"e4\", \"text\": \"PyTorch\", \"type\": \"FRAMEWORK\"}\n",
        "        ]\n",
        "    }\n",
        "]\n",
        "\n",
        "# Build graph from conversations\n",
        "builder = ContextGraphBuilder()\n",
        "graph = builder.build_from_conversations(\n",
        "    conversations,\n",
        "    link_entities=True,\n",
        "    extract_intents=True\n",
        ")\n",
        "\n",
        "print(f\"‚úÖ Built graph from {len(conversations)} conversations\")\n",
        "print(f\"   - Nodes: {graph['statistics']['node_count']}\")\n",
        "print(f\"   - Edges: {graph['statistics']['edge_count']}\")\n",
        "\n",
        "# Store conversations in memory\n",
        "for conv in conversations:\n",
        "    memory.store(\n",
        "        conv[\"content\"],\n",
        "        metadata={\n",
        "            \"type\": \"conversation\",\n",
        "            \"conversation_id\": conv[\"id\"],\n",
        "            \"timestamp\": conv[\"timestamp\"]\n",
        "        },\n",
        "        entities=conv.get(\"entities\", [])\n",
        "    )\n",
        "\n",
        "print(f\"\\n‚úÖ Stored {len(conversations)} conversations in memory\")\n",
        "\n",
        "# Retrieve conversation history\n",
        "history = memory.get_conversation_history(conversation_id=\"conv1\")\n",
        "print(f\"\\nüìã Conversation History for conv1: {len(history)} items\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 9.4 Entity Web Construction\n",
        "\n",
        "Build a complete entity web showing all entity connections and relationships.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize linker\n",
        "linker = EntityLinker(\n",
        "    knowledge_graph=kg,\n",
        "    similarity_threshold=0.8\n",
        ")\n",
        "\n",
        "# Define entities\n",
        "entities = [\n",
        "    {\"id\": \"e1\", \"text\": \"Python\", \"type\": \"PROGRAMMING_LANGUAGE\"},\n",
        "    {\"id\": \"e2\", \"text\": \"Machine Learning\", \"type\": \"CONCEPT\"},\n",
        "    {\"id\": \"e3\", \"text\": \"TensorFlow\", \"type\": \"FRAMEWORK\"},\n",
        "    {\"id\": \"e4\", \"text\": \"PyTorch\", \"type\": \"FRAMEWORK\"},\n",
        "    {\"id\": \"e5\", \"text\": \"Deep Learning\", \"type\": \"CONCEPT\"},\n",
        "]\n",
        "\n",
        "# Link entities\n",
        "linked = linker.link(\"\", entities=entities)\n",
        "\n",
        "# Create explicit links\n",
        "linker.link_entities(\"e1\", \"e2\", \"used_for\", confidence=0.9)\n",
        "linker.link_entities(\"e3\", \"e2\", \"implements\", confidence=0.95)\n",
        "linker.link_entities(\"e4\", \"e2\", \"implements\", confidence=0.94)\n",
        "linker.link_entities(\"e3\", \"e5\", \"implements\", confidence=0.92)\n",
        "linker.link_entities(\"e4\", \"e5\", \"implements\", confidence=0.91)\n",
        "linker.link_entities(\"e3\", \"e4\", \"related_to\", confidence=0.8)\n",
        "\n",
        "# Build entity web\n",
        "web = linker.build_entity_web()\n",
        "\n",
        "print(f\"‚úÖ Entity Web Statistics:\")\n",
        "print(f\"   - Total entities: {web['statistics']['total_entities']}\")\n",
        "print(f\"   - Total links: {web['statistics']['total_links']}\")\n",
        "\n",
        "print(f\"\\nüìã Entity Details:\")\n",
        "for entity_id, info in web['entities'].items():\n",
        "    print(f\"\\n   Entity {entity_id}:\")\n",
        "    print(f\"     - URI: {info.get('uri', 'N/A')}\")\n",
        "    print(f\"     - Links: {info.get('links', 0)}\")\n",
        "    print(f\"     - Type: {info.get('type', 'N/A')}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 9.5 Using Methods for Complete Workflow\n",
        "\n",
        "Use the methods submodule for a streamlined workflow.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Complete workflow using methods submodule\n",
        "\n",
        "# 1. Build context graph\n",
        "graph = methods.build_context_graph(\n",
        "    entities=entities,\n",
        "    relationships=relationships,\n",
        "    method=\"hybrid\"\n",
        ")\n",
        "print(f\"‚úÖ Step 1: Built graph with {graph['statistics']['node_count']} nodes\")\n",
        "\n",
        "# 2. Store memory\n",
        "memory_id = methods.store_memory(\n",
        "    \"User conversation about Python and machine learning\",\n",
        "    vector_store=vs,\n",
        "    knowledge_graph=kg,\n",
        "    method=\"store\",\n",
        "    metadata={\"type\": \"conversation\", \"conversation_id\": \"conv_127\"}\n",
        ")\n",
        "print(f\"‚úÖ Step 2: Stored memory with ID: {memory_id}\")\n",
        "\n",
        "# 3. Retrieve context\n",
        "results = methods.retrieve_context(\n",
        "    \"Python programming\",\n",
        "    memory_store=memory,\n",
        "    knowledge_graph=kg,\n",
        "    vector_store=vs,\n",
        "    method=\"hybrid\",\n",
        "    max_results=5\n",
        ")\n",
        "print(f\"‚úÖ Step 3: Retrieved {len(results)} context items\")\n",
        "\n",
        "# 4. Link entities\n",
        "linked = methods.link_entities(\n",
        "    entities,\n",
        "    knowledge_graph=kg,\n",
        "    method=\"knowledge_graph\"\n",
        ")\n",
        "print(f\"‚úÖ Step 4: Linked {len(linked)} entities\")\n",
        "\n",
        "print(f\"\\nüéâ Complete workflow executed successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìö Summary\n",
        "\n",
        "In this notebook, we've covered:\n",
        "\n",
        "### ‚úÖ What We Learned\n",
        "\n",
        "1. **Context Graph Construction**\n",
        "   - Building graphs from entities, relationships, and conversations\n",
        "   - Manual graph construction with nodes and edges\n",
        "   - Graph traversal and querying\n",
        "\n",
        "2. **Agent Memory Management**\n",
        "   - Storing memories with metadata and entities\n",
        "   - Retrieving memories with vector similarity search\n",
        "   - Conversation history management\n",
        "   - Memory cleanup and statistics\n",
        "\n",
        "3. **Context Retrieval**\n",
        "   - Hybrid retrieval combining multiple sources\n",
        "   - Graph expansion for related entities\n",
        "   - Multi-hop context discovery\n",
        "\n",
        "4. **Entity Linking**\n",
        "   - URI assignment for entities\n",
        "   - Similarity-based and graph-based linking\n",
        "   - Entity web construction\n",
        "   - Cross-document entity linking\n",
        "\n",
        "5. **Methods Submodule**\n",
        "   - Convenient functions for all operations\n",
        "   - Multiple algorithm support\n",
        "   - Method discovery and retrieval\n",
        "\n",
        "6. **Registry System**\n",
        "   - Registering custom methods\n",
        "   - Method management and discovery\n",
        "\n",
        "7. **Configuration**\n",
        "   - Global and method-specific settings\n",
        "   - Environment variable support\n",
        "\n",
        "### üéØ Key Takeaways\n",
        "\n",
        "- The context module provides a complete solution for building context-aware agents\n",
        "- Multiple approaches (classes vs. methods) for different use cases\n",
        "- Extensible architecture with custom method registration\n",
        "- Hybrid retrieval provides the best context quality\n",
        "- Entity linking enables cross-document knowledge integration\n",
        "\n",
        "### üìñ Next Steps\n",
        "\n",
        "- Explore the [API Reference](https://semantica.readthedocs.io/reference/context/) for detailed documentation\n",
        "- Check out advanced use cases in the cookbook\n",
        "- Build your own custom context methods\n",
        "- Integrate with other Semantica modules for complete workflows\n",
        "\n",
        "---\n",
        "\n",
        "**Happy Context Engineering! üöÄ**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
